{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "formal-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 30 12:44:49 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA Tesla V1...  On   | 00000000:15:00.0 Off |                    0 |\n",
      "| N/A   48C    P0   274W / 300W |  12796MiB / 32510MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA Tesla V1...  On   | 00000000:16:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    56W / 300W |   6469MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA Tesla V1...  On   | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    64W / 300W |  27592MiB / 32510MiB |     22%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA Tesla V1...  On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   52C    P0   291W / 300W |  10264MiB / 32510MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      8402      C   ...python/3.6.13/bin/python3    12793MiB |\n",
      "|    1   N/A  N/A      5201      C   ...earning/.venv/bin/python3     1813MiB |\n",
      "|    1   N/A  N/A      6818      C   .../python/3.8.5/bin/python3     1931MiB |\n",
      "|    1   N/A  N/A      7492      C   ...earning/.venv/bin/python3     1549MiB |\n",
      "|    1   N/A  N/A     25970      C   ...oxel2mesh/v2m/bin/python3     1173MiB |\n",
      "|    2   N/A  N/A     13003      C   ...995_torch_gpu/bin/python3    27589MiB |\n",
      "|    3   N/A  N/A      8402      C   ...python/3.6.13/bin/python3    10261MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%env CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compound-generation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "raising-black",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from WaveNetTTS.model import WaveNet\n",
    "import os\n",
    "import random\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "second-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12)\n",
    "os.environ['PYTHONHASHSEED'] = str(12)\n",
    "np.random.seed(12)\n",
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sixth-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /zhome/22/c/137477/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "sp_freq = 4000\n",
    "seq_len = 4000\n",
    "bins = 128\n",
    "batch_size = 58\n",
    "channels = 256\n",
    "kernel_size = 2\n",
    "dilation_depth = 9\n",
    "blocks = 2\n",
    "condition_size = 256\n",
    "\n",
    "MuLawEncoding = torchaudio.transforms.MuLawEncoding(quantization_channels=bins)\n",
    "Resample = torchaudio.transforms.Resample(22050, sp_freq)\n",
    "\n",
    "hugging_face_model = 'bert-base-uncased'#'distilbert-base-uncased'#\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', hugging_face_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inclusive-colonial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /zhome/22/c/137477/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp.grad_scaler import GradScaler\n",
    "from torch.cuda.amp.autocast_mode import autocast\n",
    "\n",
    "scaler = GradScaler()\n",
    "from transformers import AdamW\n",
    "\n",
    "model = WaveNet(quantization_bins=bins, kernel_size=kernel_size, channels=channels, dilation_depth=dilation_depth, blocks=blocks, condition_size=condition_size, global_condition=True, local_condition=True)\n",
    "model = model.to(device)\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [{\n",
    "    'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay) and not 'bert' in n],\n",
    "    'weight_decay': 0.01,\n",
    "    'lr': 1e-4\n",
    "}, {\n",
    "    'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay) and not 'bert' in n],\n",
    "    'weight_decay': 0.0,\n",
    "    'lr': 1e-4\n",
    "}, {\n",
    "    'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay) and 'bert' in n],\n",
    "    'weight_decay': 0.01,\n",
    "    'lr': 5e-5\n",
    "}, {\n",
    "    'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay) and 'bert' in n],\n",
    "    'weight_decay': 0.0,\n",
    "    'lr': 5e-5\n",
    "}]\n",
    "optim = AdamW(optimizer_grouped_parameters, correct_bias=False, eps=1e-8)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "active-length",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 123869568\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainable parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "medieval-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch_in):\n",
    "    y_true_out = []\n",
    "    gc_out = []\n",
    "    lc_out = []\n",
    "    for waveform, _, _, transcript in batch_in:\n",
    "        #Mu Law Encoding of waveform\n",
    "        y_true = MuLawEncoding(Resample(waveform[0])).to(device)\n",
    "        #Trim random segment of the waveform with length seq_len\n",
    "        random_idx = np.random.randint(len(y_true)-seq_len)\n",
    "        y_true_trim = y_true[random_idx:random_idx+seq_len]\n",
    "\n",
    "        y_true_out.append(y_true_trim)\n",
    "\n",
    "        #Tokenize the transcript with the BERT tokenizer\n",
    "        tokens = tokenizer(transcript, return_attention_mask=False, return_token_type_ids=False,return_tensors='pt')['input_ids'].to(device)\n",
    "\n",
    "        #Feed into sentence embedding class\n",
    "        gc_embed, lc_embed = model.sentence_embedding(tokens)\n",
    "\n",
    "        gc_out.append(gc_embed)\n",
    "\n",
    "        #Interpolate the locally conditioned signal from BERT so it fits with the waveform size and then trim the same portion of the signal as for the waveform.\n",
    "        lc_embed = F.interpolate(lc_embed, size=waveform.size(1))[:,:,random_idx:random_idx+seq_len]\n",
    "        lc_out.append(lc_embed)\n",
    "    return torch.stack(y_true_out,0), torch.cat(gc_out, 0), torch.cat(lc_out, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cardiovascular-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchaudio.datasets.LJSPEECH('', download=False)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-session",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [13:18<00:00,  3.53s/it, Loss: 2.6827635765075684, Receptive Field: 1022, Learned Size: 2978]\n",
      "100%|██████████| 226/226 [13:17<00:00,  3.53s/it, Loss: 2.506441831588745, Receptive Field: 1022, Learned Size: 2978] \n",
      "100%|██████████| 226/226 [13:20<00:00,  3.54s/it, Loss: 2.4744057655334473, Receptive Field: 1022, Learned Size: 2978]\n",
      "100%|██████████| 226/226 [13:40<00:00,  3.63s/it, Loss: 2.405155658721924, Receptive Field: 1022, Learned Size: 2978] \n",
      " 90%|████████▉ | 203/226 [11:56<01:21,  3.53s/it, Loss: 2.4261863231658936, Receptive Field: 1022, Learned Size: 2978]"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "while True:\n",
    "    with tqdm(iter(dataloader)) as t_bar:\n",
    "        for y_true, gc, lc in t_bar:\n",
    "            optim.zero_grad()\n",
    "            \n",
    "            y_true, gc, lc = y_true.to(device), gc.to(device), lc.to(device)\n",
    "            # Model predictions\n",
    "            y_preds = model(y_true, gc=gc, lc=lc)\n",
    "\n",
    "            # Calculates loss. The whole indexation show is just to align predictions with the true values.\n",
    "            loss = criterion(y_preds[:, :, :-1], y_true[:, -y_preds.size(2)+1:])\n",
    "            \n",
    "            \n",
    "            #scaler.scale(loss).backward()\n",
    "            #scaler.step(optim)\n",
    "            #scaler.update()\n",
    "            \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            # Updates\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            \n",
    "            t_bar.set_postfix_str(f'Loss: {loss.item()}, Receptive Field: {model.receptive_field}, Learned Size: {y_preds.size(2)}')\n",
    "    torch.save({'model':model.state_dict(), 'optim':optim.state_dict()}, f'LJ_speech_WaveNet_{datetime.now().strftime(\"%d-%m-%Y\")}-seq_L{seq_len}-bins{bins}-batch{batch_size}-C{channels}-k{kernel_size}-dil{dilation_depth}b{blocks}-cs{condition_size}-sp_freq{sp_freq}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
